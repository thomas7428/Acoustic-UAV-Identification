# Configuration GPU AMD RX7600 pour TensorFlow

## ‚úÖ Configuration R√©ussie

Votre GPU AMD RX7600 est maintenant configur√© et fonctionnel pour l'entra√Ænement TensorFlow !

### √âtat actuel
- **GPU**: AMD Radeon RX 7600 (gfx1102)
- **ROCm**: 6.17.7 (pr√©-install√© sur Bazzite)
- **TensorFlow-ROCm**: 2.20.0-dev0+selfbuilt (dans container Podman)
- **Utilisation GPU**: 100% pendant l'entra√Ænement ‚úÖ

## Architecture de la solution

### Pourquoi un container ?
TensorFlow-ROCm n'est plus disponible via `pip install`. La seule m√©thode support√©e est d'utiliser les images Docker/Podman officielles.

### Structure
```
Host (Bazzite)
‚îú‚îÄ‚îÄ ROCm 6.17.7 (drivers syst√®me)
‚îú‚îÄ‚îÄ Podman 5.7.1
‚îî‚îÄ‚îÄ Container: acoustic-uav-rocm
    ‚îú‚îÄ‚îÄ Base: docker.io/rocm/tensorflow:latest
    ‚îú‚îÄ‚îÄ TensorFlow 2.20.0 + ROCm
    ‚îî‚îÄ‚îÄ D√©pendances Python (sklearn, librosa, pandas, etc.)
```

## Fichiers cr√©√©s

### 1. `Dockerfile.rocm`
Image personnalis√©e qui √©tend l'image ROCm officielle avec nos d√©pendances:
- scikit-learn
- librosa
- pandas, numpy, matplotlib, seaborn
- audiomentations

### 2. `container_requirements.txt`
Liste des packages Python √† installer dans le container.

### 3. `gpu.sh`
Script autonome pour tester et utiliser le GPU:
```bash
./gpu.sh --test                              # Tester le GPU
./gpu.sh --script "mon_script.py"            # Ex√©cuter un script avec GPU
```

### 4. Modifications de `run_full_pipeline.sh`
Le pipeline d√©tecte automatiquement le GPU et l'utilise si disponible:
- Fonction `check_gpu_support()`: D√©tecte ROCm + Podman + GPU
- Fonction `run_python()`: Route les scripts via Podman si GPU disponible
- Transparent: aucun changement n√©cessaire dans vos scripts Python

## Utilisation

### Entra√Ænement avec GPU (automatique)
```bash
./run_full_pipeline.sh --models EFFICIENTNET
```

Le pipeline d√©tecte automatiquement le GPU et affiche:
```
[‚úì] GPU AMD d√©tect√© - Entra√Ænement avec acc√©l√©ration GPU activ√©
[INFO] Ex√©cution avec GPU: 2 - Model Training/EfficientNet_Trainer.py
```

### V√©rifier l'utilisation du GPU
```bash
rocm-smi --showuse
# GPU[0] : GPU use (%): 100
```

### Entra√Æner un mod√®le sp√©cifique
```bash
# Un seul mod√®le
./run_full_pipeline.sh --skip-dataset --skip-features --models EFFICIENTNET

# Plusieurs mod√®les en s√©quentiel
./run_full_pipeline.sh --models CNN,RNN,CRNN

# Plusieurs mod√®les en parall√®le
./run_full_pipeline.sh --models CNN,RNN,CRNN --parallel
```

## Configuration technique

### HSA_OVERRIDE_GFX_VERSION=11.0.2
Votre RX7600 utilise l'architecture gfx1102 (RDNA 3), plus r√©cente que celle pour laquelle l'image ROCm a √©t√© compil√©e. Cette variable d'environnement force la compatibilit√©.

### Devices et permissions
```bash
--device=/dev/kfd          # AMD GPU compute device
--device=/dev/dri          # Direct Rendering Infrastructure
--group-add video          # Groupe video pour acc√®s GPU
--security-opt label=disable  # N√©cessaire sur Fedora/Bazzite
```

### Volume mount
```bash
-v $(pwd):/workspace:rw    # Monte le r√©pertoire projet dans le container
-w /workspace              # D√©finit le r√©pertoire de travail
```

## Performance

### Avant (CPU)
- Python 3.12.2 + TensorFlow 2.20.0 (CPU uniquement)
- Pas d'acc√©l√©ration mat√©rielle

### Apr√®s (GPU)
- AMD Radeon RX 7600 avec 7404 MB VRAM
- TensorFlow-ROCm 2.20.0 avec support XLA
- Utilisation GPU: 100% pendant l'entra√Ænement
- **Acc√©l√©ration significative** üöÄ

## Logs d'entra√Ænement

Les logs montrent clairement l'utilisation du GPU:
```
I0000 ... gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 
  with 7404 MB memory:  -> device: 0, name: AMD Radeon RX 7600, pci bus id: 0000:00:07.0

I0000 ... service.cc:171] StreamExecutor device (0): AMD Radeon RX 7600, AMDGPU ISA version: gfx1102

I0000 ... device_compiler.h:196] Compiled cluster using XLA!
```

## D√©pannage

### RNN/LSTM sur ROCm: "MIOpen only supports packed input output"

**Probl√®me**: Les mod√®les utilisant LSTM/GRU (RNN, CRNN, Attention_CRNN) g√©n√®rent une erreur:
```
ROCm MIOpen only supports packed input output.
```

**Solution**: Ajout√© `use_cudnn=False` aux couches LSTM pour forcer l'impl√©mentation Python au lieu de MIOpen. Cela fonctionne sur GPU mais est l√©g√®rement plus lent que l'optimisation cuDNN/MIOpen.

**Fichiers modifi√©s**:
- [RNN_Trainer.py](2%20-%20Model%20Training/RNN_Trainer.py)
- [CRNN_Trainer.py](2%20-%20Model%20Training/CRNN_Trainer.py)
- [Attention_CRNN_Trainer.py](2%20-%20Model%20Training/Attention_CRNN_Trainer.py)

**Mod√®les non affect√©s** (fonctionnent √† pleine vitesse GPU):
- ‚úÖ CNN
- ‚úÖ EfficientNet
- ‚úÖ MobileNet
- ‚úÖ Conformer
- ‚úÖ TCN

### Le GPU n'est pas d√©tect√©
```bash
# V√©rifier ROCm
rocm-smi

# V√©rifier l'image Podman
podman images | grep acoustic-uav-rocm

# Reconstruire l'image
podman build -t acoustic-uav-rocm -f Dockerfile.rocm .
```

### Erreur "No module named 'sklearn'"
L'image de base ne contient pas nos d√©pendances. Il faut utiliser `acoustic-uav-rocm` et pas `docker.io/rocm/tensorflow:latest`.

```bash
# V√©rifier que l'image personnalis√©e existe
podman images | grep acoustic-uav-rocm

# Si n√©cessaire, la reconstruire
podman build -t acoustic-uav-rocm -f Dockerfile.rocm .
```

### Container lent au premier lancement
XLA (Accelerated Linear Algebra) compile les kernels GPU optimis√©s au premier lancement. C'est normal et ne se produit qu'une fois. Les lancements suivants seront rapides.

## Commandes utiles

```bash
# Surveiller le GPU en temps r√©el
watch -n 1 rocm-smi --showuse

# Voir tous les GPU
rocm-smi --showproductname

# Temp√©rature GPU
rocm-smi --showtemp

# Logs du pipeline
tail -f logs/pipeline_*.log

# Arr√™ter un entra√Ænement
pkill -f "python3 /workspace"
# ou
kill <PID>

# Nettoyer les containers stopp√©s
podman container prune

# Nettoyer les images inutilis√©es
podman image prune
```

## Maintenance

### Mettre √† jour l'image ROCm
```bash
podman pull docker.io/rocm/tensorflow:latest
podman build -t acoustic-uav-rocm -f Dockerfile.rocm .
```

### Ajouter des d√©pendances Python
1. Modifier `container_requirements.txt`
2. Reconstruire l'image:
   ```bash
   podman build -t acoustic-uav-rocm -f Dockerfile.rocm .
   ```

## R√©f√©rences

- [ROCm Documentation](https://rocmdocs.amd.com/)
- [TensorFlow ROCm Port](https://github.com/ROCm/tensorflow-upstream)
- [AMD GPU Support Matrix](https://github.com/ROCm/ROCm#hardware-and-software-support)

---

**Date**: 13 janvier 2026  
**Statut**: ‚úÖ Op√©rationnel  
**GPU**: AMD Radeon RX 7600 (gfx1102)  
**System**: Bazzite Linux
