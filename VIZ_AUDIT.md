# Audit du Dossier Visualisation (6 - Visualization/)
**Date**: 2026-01-10

---

## üìä Vue d'ensemble

**13 scripts Python** | ~3600 lignes total

### Scripts de Run (2 runners)
1. **run_all_visualizations.py** (151 lignes) - Runner moderne avec imports directs
2. **run_enhanced_visualizations.py** (125 lignes) - Runner subprocess avec pipeline

### Scripts Core (11 visualizers)
| Script | Lignes | Type | Statut |
|--------|--------|------|--------|
| performance_comparison.py | 640 | Core/Legacy | üü° **Obsol√®te partiel** |
| performance_comparison_best.py | 359 | Core | ‚úÖ **Moderne** |
| generate_html_report.py | 525 | Generator | ‚ö†Ô∏è **√Ä am√©liorer** |
| modern_threshold_calibration.py | 302 | Analysis | ‚úÖ **OK** |
| modern_dataset_analysis.py | 300 | Analysis | ‚úÖ **OK** |
| modern_audio_examples.py | 298 | Generator | ‚úÖ **OK** |
| model_comparison_plots.py | 259 | Plots | ‚úÖ **OK** |
| snr_distribution.py | 218 | Plots | ‚úÖ **OK** |
| threshold_calibration_comparison.py | 180 | Plots | ‚úÖ **OK** |
| select_best_results.py | 161 | Utility | ‚úÖ **OK** |
| quick_viz.py | 76 | Launcher | ‚ö†Ô∏è **D√©pend script obsol√®te** |

---

## üî¥ PROBL√àMES IDENTIFI√âS

### 1. **REDONDANCE: Deux Runners avec Approches Diff√©rentes**

#### `run_all_visualizations.py` (151 lignes)
```python
# Approche: imports directs
import modern_dataset_analysis
import modern_audio_examples
import modern_threshold_calibration
import performance_comparison

# Puis appelle:
modern_dataset_analysis.main()
performance_comparison.main()
```

**Probl√®mes**:
- Importe `performance_comparison` (le gros script legacy de 640 lignes)
- M√©lange ancien et nouveau code
- Gestion d'erreur try/except cache les probl√®mes

#### `run_enhanced_visualizations.py` (125 lignes)
```python
# Approche: subprocess
pipeline = [
    ("performance_comparison_best.py", "Step 1..."),
    ("threshold_calibration_comparison.py", "Step 3..."),
    ("model_comparison_plots.py", "Step 4..."),
    # ...
    ("generate_html_report.py", "Step 8..."),
]

for script, description in pipeline:
    subprocess.run([sys.executable, script])
```

**Probl√®mes**:
- Utilise subprocess (plus lent, isolation excessive)
- Pipeline hardcod√©
- Pas de gestion des d√©pendances entre √©tapes
- Num√©rotation saute Step 2 (??!)

**Recommandation**: **Fusionner en UN SEUL runner moderne**

---

### 2. **performance_comparison.py - Script Legacy Complexe (640 lignes)**

**Utilis√© par**:
- `run_all_visualizations.py` (l'ancien runner)
- `quick_viz.py` (launcher de presets)

**Probl√®mes**:
- 640 lignes monolithiques
- Parse arguments complexes (--models, --splits, --thresholds, --all)
- G√©n√®re BEAUCOUP de PNGs (un par threshold √ó mod√®le √ó split)
- Approche "tout ou rien" avec flag `--all`
- **Redondant avec `performance_comparison_best.py`** qui fait la m√™me chose mais mieux

**Code suspect**:
```python
# Ligne 589: main() avec argparse massif
parser.add_argument('--all', action='store_true')
parser.add_argument('--models', nargs='+', choices=['CNN', 'RNN', ...])
parser.add_argument('--splits', nargs='+', choices=['train', 'val', 'test'])
parser.add_argument('--thresholds', nargs='+', type=float)
# ... 20+ arguments
```

**Recommandation**: **D√©pr√©cier et rediriger vers performance_comparison_best.py**

---

### 3. **quick_viz.py - D√©pend du Script Obsol√®te**

```python
SCRIPT_PATH = Path(__file__).parent / "performance_comparison.py"  # ‚Üê Legacy!

PRESETS = {
    "all": {"args": ["--all"]},
    "cnn-test": {"args": ["--models", "CNN", "--splits", "test"]},
    # ...
}

def main():
    cmd = [sys.executable, str(SCRIPT_PATH)] + args
    subprocess.run(cmd)
```

**Probl√®me**: Lance `performance_comparison.py` (l'ancien script de 640 lignes)

**Recommandation**: **Mettre √† jour pour utiliser performance_comparison_best.py**

---

### 4. **generate_html_report.py - Approche Base64 Lourde (525 lignes)**

```python
def encode_image_to_base64(image_path):
    """Encode une image en base64 pour l'int√©gration dans le HTML."""
    with open(image_path, 'rb') as f:
        image_data = f.read()
    return base64.b64encode(image_data).decode('utf-8')

# Puis dans le HTML:
html_content = f"""
<img src="data:image/png;base64,{encoded_images['threshold_calibration']}" alt="...">
"""
```

**Probl√®mes**:
1. **Base64 gonfl e la taille** - Une image de 500 KB ‚Üí 667 KB en base64
2. **HTML devient √©norme** - Plusieurs MB pour un seul fichier
3. **Pas portable** - Impossible de sauvegarder les images s√©par√©ment
4. **Lent √† charger** - Navigateur doit d√©coder le base64
5. **Dur √† d√©boguer** - Impossible de voir les images directement

**Approche moderne** (comme `modern_audio_examples.py`):
```python
# Copier les images dans un dossier
shutil.copy(image_path, output_dir / "images" / image_name)

# Dans le HTML:
<img src="./images/threshold_calibration.png" alt="...">
```

**Recommandation**: **Refactorer pour utiliser chemins relatifs au lieu de base64**

**Autres probl√®mes HTML**:
- CSS inline massif (180+ lignes, lignes 124-304)
- Pas responsive pour mobile
- Hardcod√© au lieu d'utiliser templates
- G√©n√©ration de HTML par concat√©nation de strings (vuln√©rable, illisible)

---

### 5. **Num√©rotation Incoh√©rente dans Pipelines**

#### `run_enhanced_visualizations.py`:
```python
pipeline = [
    ("performance_comparison_best.py", "Step 1: Performance Analysis"),
    ("threshold_calibration_comparison.py", "Step 3: Threshold..."),  # ‚Üê Step 2 ???
    ("model_comparison_plots.py", "Step 4: Model..."),
    ("snr_distribution.py", "Step 5: SNR..."),
    ("modern_dataset_analysis.py", "Step 6: Dataset..."),
    ("modern_threshold_calibration.py", "Step 7: Modern..."),
    ("generate_html_report.py", "Step 8: Generate HTML"),
]
```

**Step 2 est manquant!** Probablement supprim√© sans renommer les suivants.

**Recommandation**: **Retirer les num√©ros ou les corriger**

---

### 6. **select_best_results.py - Utilitaire Isol√© (161 lignes)**

**R√¥le**: G√©n√®re `best_results_summary.json` en analysant tous les JSONs de performance.

**Probl√®me**: 
- Pas appel√© par les runners!
- Doit √™tre lanc√© manuellement avant les visualizations
- **Devrait faire partie du pipeline automatique**

**Recommandation**: **Int√©grer dans le runner principal comme √©tape 0**

---

### 7. **Incoh√©rence dans --best-only Flag**

#### `run_all_visualizations.py`:
```python
parser.add_argument('--best-only', action='store_true', default=True,
                    help='Run reduced visualizations using only best thresholds (default: True)')

if args.best_only:
    import performance_comparison_best as pc_best
    pc_best.main()
else:
    performance_comparison.main()  # ‚Üê Lance l'ancien script!
```

**Probl√®me**: Flag `--best-only` est True par d√©faut, donc:
- `python run_all_visualizations.py` ‚Üí utilise `performance_comparison_best.py` ‚úÖ
- `python run_all_visualizations.py --no-best-only` ‚Üí utilise l'ancien `performance_comparison.py` ‚ö†Ô∏è

**Confusion**: L'ancien script est accessible mais d√©courag√©

---

## ‚úÖ CE QUI FONCTIONNE BIEN

### Scripts "Modern" (bien con√ßus):
1. **performance_comparison_best.py** (359 lignes)
   - Charge `best_results_summary.json`
   - G√©n√®re plots clairs et utiles
   - Utilise `config.PERFORMANCE_DIR` centralis√©
   - Approche "best threshold only" √©vite explosion de PNGs

2. **modern_dataset_analysis.py** (300 lignes)
   - Analyse composition dataset
   - Plots clairs (distributions, SNR, cat√©gories)
   - Auto-suffisant

3. **modern_audio_examples.py** (298 lignes)
   - G√©n√®re HTML + audio embeddings
   - Copie fichiers WAV
   - **Bonne approche**: fichiers s√©par√©s, pas de base64
   - Structure propre: outputs/audio_examples/

4. **modern_threshold_calibration.py** (302 lignes)
   - Recommandations threshold intelligentes
   - Multi-crit√®res (F1, accuracy, balanced)
   - G√©n√®re JSON + TXT + PNG

5. **model_comparison_plots.py** (259 lignes)
   - Comparaisons visuelles entre mod√®les
   - Bien structur√©, r√©utilisable

6. **snr_distribution.py** (218 lignes)
   - Analyse SNR par cat√©gorie/distance
   - Visualisation claire

7. **threshold_calibration_comparison.py** (180 lignes)
   - Plots impact des thresholds
   - Compl√©mentaire √† modern_threshold_calibration

---

## üéØ RECOMMENDATIONS PRIORITAIRES

### Priority 1: **Simplifier les Runners (HIGH)**
**Action**: Fusionner les deux runners en UN SEUL moderne

**Nouveau fichier**: `run_visualizations.py` (remplace les 2 actuels)

**Approche**:
```python
#!/usr/bin/env python3
"""
Unified Visualization Runner
Lance toutes les visualisations modernes dans le bon ordre.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
import config

# Import des scripts modernes uniquement
import select_best_results
import performance_comparison_best
import threshold_calibration_comparison
import model_comparison_plots
import snr_distribution
import modern_dataset_analysis
import modern_threshold_calibration
import generate_html_report

def main():
    """Pipeline de visualisation complet."""
    
    print("="*80)
    print("  VISUALIZATION PIPELINE")
    print("="*80)
    
    steps = [
        ("Select Best Results", select_best_results.main),
        ("Performance Comparison", performance_comparison_best.main),
        ("Threshold Calibration Comparison", threshold_calibration_comparison.main),
        ("Model Comparison Plots", model_comparison_plots.main),
        ("SNR Distribution", snr_distribution.main),
        ("Dataset Analysis", modern_dataset_analysis.main),
        ("Threshold Calibration", modern_threshold_calibration.main),
        ("HTML Report", generate_html_report.main),
    ]
    
    for i, (name, func) in enumerate(steps, 1):
        print(f"\n[{i}/{len(steps)}] {name}...")
        try:
            func()
            print(f"‚úì {name} completed")
        except Exception as e:
            print(f"‚úó {name} failed: {e}")
    
    print("\n" + "="*80)
    print("‚úì Pipeline complete!")
```

**B√©n√©fices**:
- ‚úÖ Un seul runner √† maintenir
- ‚úÖ Imports directs (plus rapide que subprocess)
- ‚úÖ Pipeline clair et ordonn√©
- ‚úÖ Inclut `select_best_results` automatiquement
- ‚úÖ Num√©rotation coh√©rente

---

### Priority 2: **D√©pr√©cier performance_comparison.py (MEDIUM)**

**Actions**:
1. Renommer: `performance_comparison.py` ‚Üí `_deprecated_performance_comparison.py`
2. Cr√©er stub avec message de redirection:
```python
#!/usr/bin/env python3
"""
DEPRECATED: Use performance_comparison_best.py instead
This script is kept for backward compatibility only.
"""
import sys
print("WARNING: This script is deprecated!")
print("Use: python performance_comparison_best.py")
print("Or run the full pipeline: python run_visualizations.py")
sys.exit(1)
```
3. Mettre √† jour `quick_viz.py` pour pointer vers `performance_comparison_best.py`

---

### Priority 3: **Refactorer generate_html_report.py (MEDIUM)**

**Actions**:
1. **Remplacer base64 par chemins relatifs**:
```python
# Au lieu de:
encoded_images['threshold'] = encode_image_to_base64(image_path)
html += f'<img src="data:image/png;base64,{encoded_images['threshold']}">'

# Faire:
shutil.copy(image_path, output_dir / "images" / "threshold_calibration.png")
html += f'<img src="./images/threshold_calibration.png">'
```

2. **Extraire le CSS dans fichier s√©par√©**:
```
outputs/
  report.html
  style.css
  images/
    threshold_calibration.png
    model_comparison.png
    ...
```

3. **Utiliser template engine** (Jinja2 ou simple format):
```python
from string import Template

template = Template(Path("report_template.html").read_text())
html = template.substitute(
    title="UAV Performance Report",
    date=datetime.now().strftime("%Y-%m-%d"),
    # ...
)
```

**B√©n√©fices**:
- ‚úÖ HTML ~10x plus petit
- ‚úÖ Images r√©utilisables s√©par√©ment
- ‚úÖ CSS modifiable sans toucher au code Python
- ‚úÖ Plus rapide √† charger
- ‚úÖ Meilleure s√©paration des responsabilit√©s

---

### Priority 4: **Mettre √† jour quick_viz.py (LOW)**

**Action**: Pointer vers les scripts modernes
```python
# Au lieu de:
SCRIPT_PATH = Path(__file__).parent / "performance_comparison.py"

# Utiliser:
SCRIPT_PATH = Path(__file__).parent / "performance_comparison_best.py"

# Ou mieux: lancer le runner complet
SCRIPT_PATH = Path(__file__).parent / "run_visualizations.py"
```

---

### Priority 5: **Corriger Num√©rotation Pipeline (LOW)**

Dans `run_enhanced_visualizations.py` (ou le nouveau runner):
```python
# Retirer les num√©ros ou corriger:
pipeline = [
    ("Select Best Results", select_best_results.main),  # Nouveau step 0
    ("Performance Analysis", performance_comparison_best.main),
    ("Threshold Calibration Comparison", threshold_calibration_comparison.main),
    ("Model Comparison", model_comparison_plots.main),
    ("SNR Distribution", snr_distribution.main),
    ("Dataset Analysis", modern_dataset_analysis.main),
    ("Modern Threshold Calibration", modern_threshold_calibration.main),
    ("HTML Report", generate_html_report.main),
]
```

---

## üìã PLAN D'ACTION D√âTAILL√â

### Phase 1: Cleanup (1-2h)
- [ ] Cr√©er `run_visualizations.py` (nouveau runner unifi√©)
- [ ] Renommer `performance_comparison.py` ‚Üí `_deprecated_performance_comparison.py`
- [ ] Cr√©er stub de redirection dans ancien fichier
- [ ] Mettre √† jour `quick_viz.py` pour pointer vers nouveau runner
- [ ] Tester le nouveau pipeline complet

### Phase 2: Am√©lioration HTML (2-3h)
- [ ] Extraire CSS dans `style.css` s√©par√©
- [ ] Cr√©er dossier `outputs/images/` pour les images
- [ ] Modifier `generate_html_report.py` pour copier images au lieu de base64
- [ ] Cr√©er template HTML s√©par√© (optionnel, ou garder string formatt√© simple)
- [ ] Tester g√©n√©ration HTML et v√©rifier taille fichier

### Phase 3: Documentation (30min)
- [ ] Mettre √† jour README.md pour refl√©ter nouveau workflow
- [ ] Ajouter exemples d'usage du nouveau runner
- [ ] Documenter les scripts obsol√®tes
- [ ] Cr√©er guide de migration

### Phase 4: Validation (1h)
- [ ] Lancer pipeline complet: `python run_visualizations.py`
- [ ] V√©rifier tous les outputs g√©n√©r√©s
- [ ] Comparer avec anciens outputs (qualit√© identique?)
- [ ] V√©rifier taille HTML report (devrait √™tre ~10x plus petit)
- [ ] Tester quick_viz presets

---

## üìä M√âTRIQUES AVANT/APR√àS

### Avant Refactoring:
- **2 runners** avec approches diff√©rentes (imports vs subprocess)
- **2 scripts performance** (640 + 359 lignes) redondants
- **HTML report**: ~2-5 MB (avec base64)
- **Pipeline**: 7-8 √©tapes (num√©rotation incoh√©rente)
- **Scripts obsol√®tes**: 1 gros (performance_comparison.py)
- **Confusion**: Quel runner utiliser? Quel script performance?

### Apr√®s Refactoring:
- **1 runner** unifi√©, approche consistente
- **1 script performance** (performance_comparison_best.py)
- **HTML report**: ~200-500 KB (chemins relatifs)
- **Pipeline**: 8 √©tapes num√©rot√©es (inclut select_best_results)
- **Scripts obsol√®tes**: Clairement marqu√©s (_deprecated)
- **Clart√©**: Un seul point d'entr√©e, workflow √©vident

---

## üîç SCRIPTS √Ä GARDER (Aucun changement)

Ces scripts sont bien con√ßus et ne n√©cessitent pas de modifications:
- ‚úÖ `performance_comparison_best.py`
- ‚úÖ `modern_dataset_analysis.py`
- ‚úÖ `modern_audio_examples.py`
- ‚úÖ `modern_threshold_calibration.py`
- ‚úÖ `model_comparison_plots.py`
- ‚úÖ `snr_distribution.py`
- ‚úÖ `threshold_calibration_comparison.py`
- ‚úÖ `select_best_results.py` (juste l'int√©grer au pipeline)

---

## üìù NOTES ADDITIONNELLES

### Architecture Actuelle (Confuse):
```
run_all_visualizations.py ‚îÄ‚îÄ‚îÄ‚ñ∫ performance_comparison.py (640 lignes, legacy)
                          ‚îî‚îÄ‚îÄ‚îÄ‚ñ∫ modern_* scripts

run_enhanced_visualizations.py ‚îÄ‚îÄ‚îÄ‚ñ∫ subprocess tous les scripts
                                     (inclut performance_comparison_best.py)

quick_viz.py ‚îÄ‚îÄ‚îÄ‚ñ∫ performance_comparison.py (legacy)
```

### Architecture Propos√©e (Claire):
```
run_visualizations.py ‚îÄ‚îÄ‚îÄ‚ñ∫ select_best_results (nouveau step 0)
                      ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ performance_comparison_best
                      ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ threshold_calibration_comparison
                      ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ model_comparison_plots
                      ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ snr_distribution
                      ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ modern_dataset_analysis
                      ‚îú‚îÄ‚îÄ‚îÄ‚ñ∫ modern_threshold_calibration
                      ‚îî‚îÄ‚îÄ‚îÄ‚ñ∫ generate_html_report (refactor√©)

quick_viz.py ‚îÄ‚îÄ‚îÄ‚ñ∫ run_visualizations.py (avec presets)

_deprecated_performance_comparison.py ‚îÄ‚îÄ‚îÄ‚ñ∫ (stub avec message)
```

---

## ‚ö° QUICK WINS (Faciles et rapides)

1. **Renommer runners** (2 min):
   - `run_all_visualizations.py` ‚Üí `_old_run_all.py`
   - `run_enhanced_visualizations.py` ‚Üí `_old_run_enhanced.py`

2. **Cr√©er nouveau runner** (15 min):
   - Copier structure de `run_all_visualizations.py`
   - Remplacer `performance_comparison` par `performance_comparison_best`
   - Ajouter `select_best_results` en step 0
   - Retirer num√©ros des steps

3. **Stub deprecation** (5 min):
   - Cr√©er `_deprecated_performance_comparison.py`
   - Message de redirection

4. **Mettre √† jour README** (10 min):
   - Pointer vers nouveau runner
   - Marquer anciens scripts comme obsol√®tes

**Total: ~30 min pour quick wins majeurs!**

---

**Fin de l'audit**
